---
title: "occstanhm_3"
author: "Richard Erickson"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{occstanhm_3}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


```{r}
#| eval: true
#| echo: false
#| warning: false
#| message: false
#| error: false
library(occstanhm)
library(tidyverse)
library(ggthemes)
```


**Warning:** This example contains a small presimulated dataset and small Stan model run to demonstrate.
These size limitations were done because of file size limitations in packages and GitHub.
We encourage you to simulate larger datasets (e.g., more units, visits) to better explore the model and understand it.


The `occstanhm_3()` function is one of two featured models in the occstanhm package.
The function fits a three-level occupancy model with both correlated detection and occupancy probabilities.
The model also allows for different coefficients across groups within the model, in contrast to the simpler models included within this package.


## Mathematical formulation

The _Occupancy model formulations_ vignette includes the equations for this model.
This may be accessed using `vignette("Occupancy model formulations", package = "occstanhm")`.

## Explanation of algorithm 

There are two major parts to the model.
First, the `reduce_sum()` function uses the `unit_loop_psi()` function to loop over unit-species combinations.
This estimates a `logit_psi` for each unit-species combination, and `logit_theta` for each sample (at the observation or y-level) and a `logit_p` for the subsamples from each sample observation at the y-level.
This involves multiple slices and loops.

* A loop goes over each unit-species combination (in parallel with up-to one combination per CPU using the `reduce_sum()` function).
* Within each unit-species combination, another loop goes over each revisit. This loop contains the `logit_psi` vectors.
* Within each revisit, a loop goes over each sample. This last loop is done so that coefficients can exist at the sample-level. This loop contains the `logit_theta` and `logit_p` vectors.

Second, the `logit_psi`, `logit_theta`, and `logit_p` vectors are mapped to their respective predictor coefficient matrices.
These matrices have a row for each unit-species combination and are expanded by the `jj` vectors.
A hyperparameter matrix allows for the correlations between coefficients to be estimated.
When each coefficient is a species at a location, this coefficient is the correlation among species.

The code also contains idiosyncrasies and other oddities to optimize and program in Stan, some of which are described in this paragraph.
The slicing/indexing is complex because Stan requires the marginalization of discrete latent parameters and the reduce sums function also requires discrete groupings.
The Cholesky decomposition for the prior requires the onion method because the default Stan method does not scale.
Calculations are moved to the `transformed parameter` block whenever possible such as the use of `logit_psi_in`, `logit_theta_in`, and `logit_p_in`.
A prior is used on `logit_psi`, `logit_theta`, and `logit_p` and priors are used on these priors to increase numerical stability.
These programming methods were used based upon reading Stan documentation, the help forum (and asking questions on the help forum), and trial and error.

## Stan implementaiton

The model is implemented using Stan.
Unlike some of the example models, this model allows for different predictor matrices.
This comes with an increase in model complexity, especially for formatting data in R.
Key parts of the Stan model by code block include:

* `functions`  
  * A custom Cholesky factor function that uses the [onion method](https://discourse.mc-stan.org/t/using-the-onion-method-in-occupancy-model-hierarchical-model/24901)
  * Custom occupancy model functions
* `data`  
  * The number of unit-species combinations
  * The number of total revisits across all unit-species combinations
  * The total number of samples in the data
  * A vector with the number of revisits per unit-species combination
  * The number of samples per reach revisits
  * The number of rows in the beta predictor matrix
  * The number of rows in the alpha predictor matrix
  * The number of rows in the delta predictor matrix
  * The number of beta coefficients
  * The number of delta coefficients
  * The binary observation  status for each sample
  * The count (integer) status for subsamples within each sample
  * The binary observation status for each revisit
  * A start-stop pair of indexing vectors for unit-species combinations at the observed (y) level. That is to say, this index takes the y data and slices it for each unit-species combination.
  * A start-stop pair of indexing vectors revisits at the observed (y) level. That is to say, this index first gets indexed for each unit using the next index pair. Then, the index is used to slice the observed (y) level data for each revisit.
  * A start-stop pair of indexing vectors that slice data at the revisit (z_obs) level for each unit-revisit. For example, the `z_obs` data needs to be sliced for each unit-species combination. This vector does that slicing. The index pair also slices the previous index pair (**This is a necessary complexity for the Stan code**).
  * a `jj` vector for psi that expands/maps each logit_psi to the prediction unit-species combination
  * The psi predictor matrix
  * The dimensions for the psi predictor matrix
  * The hyper parameter predictor matrix that maps the beta coefficients to their hyperparameters
  * a `jj` vector for theta that expands/maps each logit_theta to the prediction at the sample level
  * The theta predictor matrix
  * The dimensions for the theta predictor matrix
  * The hyper parameter predictor matrix that maps the beta coefficients to their hyperparameters
  * The `jj` vector for p that expands/maps each logit_p to the prediction at the sample level
  * The p predictor matrix
  * The dimensions for the p predictor matrix
  * The priors for the psi hyper parameters (and dimensions) and also the Cholesky matrix prior, eta
  * The priors for the theta hyper parameters (and dimensions) and also the Cholesky matrix prior, eta
  * The priors for the p hyper parameters (and dimensions) and also the Cholesky matrix prior, eta
  * The priors for the logit_psi, logit_theta, and logit_p and the prior for this prior
  * The grain size for the reduce_sum setting
  

```{r comment=''}
#| echo: false
system.file("occstanhm_3.stan", package = "occstanhm") |>
  readLines() |>
  cat(sep = "\n")
```

## Data formatting

The model allows for multiple "observers" with subsampling. Nomenclature can become confusing due to different possible designs and sources of replication.

The highest level of replication are "units" such as lakes, habitat patches, or other locations.
This may be resampled through different "subunits" such as locations within a lake, plots within a forest, or temporal revisits.
Additionally, each subunit may be resampled through "samples".
These subsamples have subsamples such as molecular replicates or subplots.


## Example Application to multiple observers

The `occstanhm_3()` function calls the `occstanhm_3.stan` model.
Formatting data can be tricky with this model because of the multiple levels of indexing necessary for Stan code.
The code for this example is included as its own file, but annotated with text here.
For compiling this vignette, the source code file may be included from the file within the package (following along, you can either copy code from this file or open the source file).

```{r, echo=FALSE}
system.file("./occstanhm_3_raw.R", package = "occstanhm") |>
  knitr::read_chunk()
```

First, this package is loaded, as well as the Tidyverse (used for data wrangling and plotting) and ggthemes (used for colorblind friendly colors):


```{r load_packages, eval=FALSE}
```

Next, data are simulated using the `sim_long_form_occ_3()` function that allows for correlated structures in the data.
For example, perhaps several ponds are treated as the `unit` for this model and each pond is revisited through space or time, and sampling occurs during each revisit:

```{r simulation, eval=FALSE}
```

The data also requires some additional formatting to create integers for input groups (Stan, unlike R, cannot work with characters and factors):

```{r sim_format, eval=FALSE}
```

**Note:** The data and model fits have been precompiled and are included in the package.

**Warning;** If you are running the code rather than using presimulated values, you will likely get different values. Although the random number generator seed has been set, this sometimes varies across machines and versions of R.

If you prefer, you may use the presimulated data:

```{r load_sim_data, eval=TRUE}
```

For a first plot, consider a single `unit` such as a pond or forest.
This `unit` has multiple sampling events or a `revist`.
Each `revisit` has multiple samples taken from it.
The raw data may be plotted from a single unit:

```{r plot_one}
```

Plots for all of the simulated units may be included using a facet with ggplot2:

```{r plot_data, fig.width=9,fig.height=9}
```

Next, the data needs to be formatted for Stan.
Group the observation-level data by unit and species to calculate the `z_obs` and one of the index pairs:

```{r summarize_stan_data_revisit_species}
```

This data frame may then be summarized a second time to obtain the number of revisits per unit and another index pair:

```{r summarize_stan_data_revisit_species_2}
```

***Tip:** Go back and understand these index pairs from the past two data frames.
These are important concepts to understand in order to understand how to slices and subset data for Stan. The index pairs provide insight in to how Stan loops over data.

A summary may also be done for species at the revisit-level:

```{r summarize_stan_data_revisit_species_3}
```

The data is also summarized at the level of the unit-species combination.
This calculates the number of samples per unit-species combination, the last index pair, and an approximate estimation for $\psi$ that does not consider imperfect detection:

```{r summarize_stan_data_unit_species}
```

The predictor matrix and hyperparameters for $\textbf{X}$ need to be created as well.
The code includes a `_psi` to help find these variables more easily with more descriptive names:

```{r x_psi_predictor}
```

Code also allows the user to check dimensions of input objects:

```{r check_psi}
```

Priors are also specified for the beta hyperparameters:

```{r beta_priors}
```

The dimension of these hyperparameters may also be checked:

```{r check_beta_priors}
```

The dimensions for the multiplication were difficult, and, these can be checked.
These are done separately because the code helped the authors debug and better understand the equations:

```{r check_beta_star}
```

A predictor matrix may be created for the theta-level coefficients:

```{r theta_coef}
```

These may be checked:

```{r theta_coef_check}
```

Also, hyperparameters may be created:

```{r theta_hyper}
```

And these checked as well:

```{r theta_check_priors}
```

A predictor matrix may also be created for the p-level coefficients:

```{r p_coef}
```

And these coefficients checked:

```{r p_coef_check}
```

The hyper parameters may be created for the p-level:

```{r p_hyper}
```

The dimensions of these parameter checked as well:

```{r p_check_priors}
```

The objects may now be saved as a list for Stan:

```{r save_as_stan}
```

***Note and warning:** The Stan outputs have been saved as part of the package.
See later code blocks for examples loading this data.
This model took approximately 5.5 hr to run on a 16-core instance and used about 8-12 CPUs for most of the run.

```{r run_stan_model, eval=FALSE}
```

The fit summary can also take many computer resources and has been saved as part of the package (even using 15 cores, this code take a few minutes to run):

```{r fit_summary, eval=FALSE}
```

Or, you may load existing simulated outputs:

```{r load_stan_outputs}
```

Fist, look at the Stan fit:

```{r model_diag}
```

Next look at the default fit summary:

```{r default_fit_summary}
```

Then sorted low to high:

```{r default_fit_summary_1}
```

Then sorted high to low:

```{ default_fit_summary_2}
```

The beta coefficients may be extracted for later plotting:

```{r beta_coef, fig.width=6, fig.height=6}
```

And the beta coefficients plotted along with the simulated $\psi$ values (That do not account for imperfect detection):

```{r beta_coef_plot, fig.width=6, fig.height=6}
```

The alpha coefficients may be extracted for later plotting:

```{r alpha_coef, fig.width=6, fig.height=6}
```

And the beta coefficients plotted along with the simulated $\psi$ values (That do not account for imperfect detection):

```{r alpha_coef_plot, fig.width=6, fig.height=6}
```

Similar results may be extracted and formatted for the p-level of the model:

```{r extract_p_coef}
```

And the p-level coefficients plotted:

```{r delta_plot, fig.width=6,fig.height=6}
```

The estimated correlations may be examined:

```{r est_corr}
```

and plotted:

```{r plot_corr, fig.width=6, fig.height=6}
```

The priors, $\sigma_p$ and $\sigma_\psi$ may be examined (these parameters can be pathological, but if they fit, then the model is likely good to go):

```{r est_sigmas}
```

Traceplots may also be displayed such as the log probability:

```{r trace_plot}
```
